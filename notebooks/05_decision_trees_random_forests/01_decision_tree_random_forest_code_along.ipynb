{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees & Random Forests - code along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/home/rodolfo/spark-3.3.1-bin-hadoop3\")\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier, DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/11 15:40:25 WARN Utils: Your hostname, rodolfo-300E5M-300E5L resolves to a loopback address: 127.0.1.1; using 192.168.15.11 instead (on interface wlp3s0)\n",
      "22/12/11 15:40:25 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/11 15:40:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/12/11 15:40:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/12/11 15:40:31 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"trees\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/11 15:42:17 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"libsvm\").load(\"../../data/sample_libsvm_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "decision_tree_classifier = DecisionTreeClassifier().fit(train)\n",
    "random_forest_classifier = RandomForestClassifier(numTrees=100).fit(train)\n",
    "gradient_boosting_classifier = GBTClassifier().fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_test_pred = decision_tree_classifier.transform(test)\n",
    "random_forest_test_pred = random_forest_classifier.transform(test)\n",
    "gradient_boosting_test_pred = gradient_boosting_classifier.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------------+-----------+----------+\n",
      "|label|            features|rawPrediction|probability|prediction|\n",
      "+-----+--------------------+-------------+-----------+----------+\n",
      "|  0.0|(692,[121,122,123...|   [32.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|   [32.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "+-----+--------------------+-------------+-----------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree_test_pred.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------------+-----------+----------+\n",
      "|label|            features|rawPrediction|probability|prediction|\n",
      "+-----+--------------------+-------------+-----------+----------+\n",
      "|  0.0|(692,[121,122,123...|  [100.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|   [99.0,1.0]|[0.99,0.01]|       0.0|\n",
      "+-----+--------------------+-------------+-----------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest_test_pred.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(692,[121,122,123...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting_test_pred.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree accuracy 0.9696969696969697\n",
      "Random forest accuracy 1.0\n",
      "Gradient boosting accuracy 0.9696969696969697\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision tree accuracy\", accuracy_evaluator.evaluate(decision_tree_test_pred))\n",
    "print(\"Random forest accuracy\", accuracy_evaluator.evaluate(random_forest_test_pred))\n",
    "print(\"Gradient boosting accuracy\", accuracy_evaluator.evaluate(gradient_boosting_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(692, {148: 0.0006, 149: 0.0012, 154: 0.0004, 174: 0.0009, 177: 0.0003, 179: 0.0005, 180: 0.0004, 210: 0.0004, 215: 0.0005, 216: 0.0065, 217: 0.0023, 234: 0.0138, 235: 0.0056, 242: 0.0005, 243: 0.0027, 244: 0.0241, 261: 0.0005, 272: 0.0161, 285: 0.0005, 290: 0.0021, 294: 0.001, 295: 0.0029, 300: 0.0366, 314: 0.001, 319: 0.0005, 322: 0.0033, 323: 0.0108, 324: 0.0005, 325: 0.0005, 328: 0.0122, 329: 0.0066, 342: 0.0037, 343: 0.001, 345: 0.0041, 346: 0.0022, 350: 0.0162, 351: 0.019, 354: 0.0007, 355: 0.0004, 356: 0.001, 357: 0.0075, 370: 0.0011, 372: 0.0001, 373: 0.0191, 374: 0.0006, 377: 0.0145, 378: 0.0429, 379: 0.0076, 380: 0.0067, 381: 0.0015, 382: 0.0025, 383: 0.0005, 384: 0.0025, 385: 0.0064, 387: 0.0028, 399: 0.0073, 400: 0.0063, 401: 0.0082, 403: 0.0006, 405: 0.0115, 406: 0.0337, 407: 0.0115, 408: 0.001, 413: 0.0064, 414: 0.0006, 415: 0.0012, 427: 0.0063, 428: 0.0083, 429: 0.0004, 431: 0.0009, 432: 0.0101, 433: 0.0382, 434: 0.0349, 435: 0.0099, 438: 0.002, 442: 0.0014, 444: 0.0011, 452: 0.0005, 453: 0.0015, 455: 0.0462, 457: 0.0072, 460: 0.008, 461: 0.0192, 462: 0.024, 463: 0.0113, 464: 0.0014, 467: 0.0011, 468: 0.0013, 469: 0.0084, 482: 0.0028, 483: 0.0416, 484: 0.0075, 485: 0.0007, 489: 0.0198, 490: 0.0258, 493: 0.0022, 496: 0.0008, 497: 0.0078, 498: 0.0012, 499: 0.0012, 509: 0.001, 510: 0.0066, 511: 0.0345, 512: 0.0182, 513: 0.0015, 516: 0.0017, 517: 0.0362, 518: 0.0522, 519: 0.0017, 521: 0.0032, 527: 0.0012, 540: 0.0103, 544: 0.0029, 545: 0.009, 546: 0.0023, 551: 0.0074, 553: 0.0007, 568: 0.0073, 571: 0.0004, 579: 0.0067, 597: 0.0112, 606: 0.0069, 622: 0.0006, 626: 0.0037, 628: 0.0015, 631: 0.0054, 633: 0.0008, 654: 0.0004, 659: 0.0006, 683: 0.0006})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_classifier.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('spark_course')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d906eeae597a8ebeffe207202bff49f0d475a3060f2355a6194de2c87e6459b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
